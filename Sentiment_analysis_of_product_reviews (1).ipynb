{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVsaNHL_HPNU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load the dataset with a different encoding\n",
        "df = pd.read_csv('Reviews.csv', encoding='latin1')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwVNdv8sawyh",
        "outputId": "e58e5cad-4318-43a9-ed82-a9d444b5efa1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "def preprocess_text(text):\n",
        "    if isinstance(text, str):  # Check if the input is a string\n",
        "        # Remove HTML tags\n",
        "        text = re.sub('<[^<]+?>', ' ', text)\n",
        "        # Remove non-alphanumeric characters and keep spaces\n",
        "        text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "        # Convert to lowercase\n",
        "        text = text.lower()\n",
        "        # Tokenize\n",
        "        tokens = word_tokenize(text)\n",
        "        # Remove stopwords\n",
        "        stop_words = set(stopwords.words('english'))\n",
        "        tokens = [token for token in tokens if token not in stop_words]\n",
        "        # Lemmatization\n",
        "        lemmatizer = WordNetLemmatizer()\n",
        "        tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "        # Join tokens back into a string\n",
        "        preprocessed_text = ' '.join(tokens)\n",
        "        return preprocessed_text\n",
        "    else:\n",
        "        return ''  # Return empty string if the input is not a string\n",
        "\n",
        "\n",
        "# Preprocess the 'Text' column\n",
        "df['Preprocessed_Text'] = df['Text'].apply(preprocess_text)\n",
        "\n",
        "# Print the preprocessed text\n",
        "print(df['Preprocessed_Text'].head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXBUiUOAIXnd",
        "outputId": "f86b8aab-41de-41ca-cba2-0792f1a51ea7"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Initialize the TF-IDF vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=1000)  # You can adjust the number of features as needed\n",
        "\n",
        "# Fit and transform the preprocessed text data\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(df['Preprocessed_Text'])\n",
        "\n",
        "# Print the shape of the TF-IDF matrix\n",
        "print(\"Shape of TF-IDF matrix:\", X_tfidf.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXuVKygBIeuF",
        "outputId": "4a9d40b6-9eae-47e1-be91-b6165521f04f"
      },
      "outputs": [],
      "source": [
        "# Optional: Print the feature names\n",
        "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "print(\"Feature names:\", feature_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoIAIiGedFN6",
        "outputId": "be1c4570-d6f3-40c8-f789-82272a2a9b53"
      },
      "outputs": [],
      "source": [
        "# Drop rows with missing values in any column\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Re-extract features and target variable after dropping missing values\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(df['Preprocessed_Text'])\n",
        "y = df['Score']\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize logistic regression model\n",
        "logistic_regression_model = LogisticRegression()\n",
        "\n",
        "# Train the model\n",
        "logistic_regression_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred_train = logistic_regression_model.predict(X_train)\n",
        "y_pred_test = logistic_regression_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
        "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "\n",
        "print(\"Train Accuracy:\", train_accuracy)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n",
        "\n",
        "# Classification report\n",
        "print(\"Classification Report for Test Data:\")\n",
        "print(classification_report(y_test, y_pred_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDVAaFyDdkIa",
        "outputId": "1709f13f-5ebd-45fd-bd70-69867d9eee23"
      },
      "outputs": [],
      "source": [
        "# Example text\n",
        "example_text = \"This product exceeded my expectations. It works perfectly and is worth every penny.\"\n",
        "\n",
        "# Preprocess the example text\n",
        "preprocessed_example_text = preprocess_text(example_text)\n",
        "\n",
        "# Vectorize the preprocessed example text\n",
        "example_text_vectorized = tfidf_vectorizer.transform([preprocessed_example_text])\n",
        "\n",
        "# Predict sentiment\n",
        "predicted_sentiment = logistic_regression_model.predict(example_text_vectorized)\n",
        "\n",
        "# Print the predicted sentiment\n",
        "print(\"Predicted Sentiment:\", predicted_sentiment)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKlaNRlJKxWB",
        "outputId": "12cc23b6-3ea1-4045-f374-acecefbceded"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "# Choose random examples from the dataset\n",
        "random.seed(42)  # For reproducibility\n",
        "random_indices = random.sample(range(len(df)), 5)  # Select 5 random indices\n",
        "random_examples = df.iloc[random_indices]\n",
        "\n",
        "# Predict sentiments for the random examples\n",
        "for index, row in random_examples.iterrows():\n",
        "    example_text = row['Text']\n",
        "    preprocessed_example_text = preprocess_text(example_text)\n",
        "    example_text_vectorized = tfidf_vectorizer.transform([preprocessed_example_text])\n",
        "    predicted_sentiment = logistic_regression_model.predict(example_text_vectorized)[0]\n",
        "    actual_sentiment = row['Score']\n",
        "    print(\"Example Text:\", example_text)\n",
        "    print(\"Actual Sentiment:\", actual_sentiment)\n",
        "    print(\"Predicted Sentiment:\", predicted_sentiment)\n",
        "    print(\"-------------------------------\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
